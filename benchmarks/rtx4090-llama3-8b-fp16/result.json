{
    "model": "Llama-3-8B-Instruct",
    "chip": "NVIDIA RTX 4090",
    "precision": "FP16",
    "batch_size": 2,
    "concurrency": 1,
    "ttft_ms": 28.6,
    "tps": 156.3,
    "power_w_avg": 285.1,
    "timestamp": "2025-01-12T17:33:42Z",
    "input_length": 128,
    "output_length": 512
}